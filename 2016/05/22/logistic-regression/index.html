<!DOCTYPE HTML>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    

    <title>Logistic Regression | </title>
    <meta name="author" content="王泽贤">
    
    <meta name="description" content="Logistic Regression
logistic regression 和 perceptron 其实是比较像的，都是只能对线性可分的数据建模，也是基于神经科学的神经元模型得来的，神经元模型图如下。不过 logistic regression 的输出结果值具有一定的解释性，可以把它理解为概率。另外一方面，logistic regression 可以很容易地扩展到对多个类建模，而 percptron 只能作为二元分类器。 logistic regression 使用 sigmoid 激活函数
\[\sigma = \frac{1}{1 + \exp^{-z}}\]">
    
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta property="og:title" content="Logistic Regression"/>
    <meta property="og:site_name" content="水幕天华"/>

    
    <meta property="og:image" content="undefined"/>
    

    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="alternate" href="/atom.xml" title="水幕天华" type="application/atom+xml">
    <link rel="stylesheet" href="/css/lib/materialize.min.css">
    <link rel="stylesheet" href="/css/lib/font-awesome.min.css">
    <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">

    
        <link rel="stylesheet" href="/css/lib/prettify-tomorrow-night-eighties.css" type="text/css">
    
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>


<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><img src="/weixin_favicon.png" style="position: absolute; left: -9999px; opacity: 0; filter: alpha(opacity=0);">

    <nav class="indigo">
    <div class="nav-wrapper">
        <a href="#" data-activates="main-menu" class="button-collapse">
            <i class="fa fa-navicon"></i>
        </a>
        <div class="">
            <a href="/" class="brand-logo hide-on-med-and-down">水幕天华</a>
            <ul class="right hide-on-med-and-down">
                
                    <li>
                        <a class="menu-home " href="/" >
                            <i class="fa fa-home "></i>
                            
                            Home
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-archive " href="/archives" >
                            <i class="fa fa-archive "></i>
                            
                            Archives
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-category category-menu" href="javascript:;" data-activates="category-menu" >
                            <i class="fa fa-bookmark "></i>
                            
                            Categories
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-reading " href="/reading" >
                            <i class="fa fa-book "></i>
                            
                            Reading
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-about " href="/about" >
                            <i class="fa fa-user "></i>
                            
                            About
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-search modal-trigger " href="#search" >
                            <i class="fa fa-search "></i>
                            
                            Search
                        </a>
                    </li>
                
            </ul>
            <div>
    <ul class="side-nav indigo darken-1" id="main-menu">
        
        <li class="side-user">
            <div class="row">
                <div class="col s4 no-padding">
                    <img class="avatar-image circle responsive-img" src="http://ww2.sinaimg.cn/small/74990035jw1f1rjkd681bj20rs0rsdhg.jpg" alt="User Avatar">
                </div>
                <div class="info col s8 valign-wrapper no-padding">
                    <div class="valign">
                        <p class="name">王泽贤</p>
                        <p class="desc">Web前端/linux/人工智能</p>
                    </div>
                </div>
            </div>
        </li>
        

        
            <li class="no-padding">
                <a class="waves-effect menu-home " href="/" >
                    <i class="fa fa-home "></i>
                    
                    Home
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-archive " href="/archives" >
                    <i class="fa fa-archive "></i>
                    
                    Archives
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-category category-menu" href="javascript:;" data-activates="category-menu" >
                    <i class="fa fa-bookmark "></i>
                    
                    Categories
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-reading " href="/reading" >
                    <i class="fa fa-book "></i>
                    
                    Reading
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-about " href="/about" >
                    <i class="fa fa-user "></i>
                    
                    About
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-search modal-trigger " href="#search" >
                    <i class="fa fa-search "></i>
                    
                    Search
                </a>
            </li>
        
    </ul>

    <ul class="side-nav indigo darken-1" id="category-menu">
    

            

            <li class="collapse-level-0" collapse-level="0">
                <a class="no-padding" href="/categories/随笔/">
                    随笔 <span class="right">2</span></a>
                </a>
            </li>

        

            <li class="collapse-level-1" collapse-level="1">
                <a class="no-padding" href="/categories/随笔/心态/">
                    心态 <span class="right">1</span></a>
                </a>
            </li>

        

            <li class="collapse-level-1" collapse-level="1">
                <a class="no-padding" href="/categories/随笔/名言/">
                    名言 <span class="right">1</span></a>
                </a>
            </li>

        

            <li class="collapse-level-0" collapse-level="0">
                <a class="no-padding" href="/categories/orgmode/">
                    orgmode <span class="right">1</span></a>
                </a>
            </li>

        

            <li class="collapse-level-0" collapse-level="0">
                <a class="no-padding" href="/categories/人工智能/">
                    人工智能 <span class="right">9</span></a>
                </a>
            </li>

        

            <li class="collapse-level-1" collapse-level="1">
                <a class="no-padding" href="/categories/人工智能/机器视觉/">
                    机器视觉 <span class="right">1</span></a>
                </a>
            </li>

        

            <li class="collapse-level-1" collapse-level="1">
                <a class="no-padding" href="/categories/人工智能/机器学习/">
                    机器学习 <span class="right">8</span></a>
                </a>
            </li>

        

            <li class="collapse-level-0" collapse-level="0">
                <a class="no-padding" href="/categories/数据可视化/">
                    数据可视化 <span class="right">1</span></a>
                </a>
            </li>

        

            <li class="collapse-level-1" collapse-level="1">
                <a class="no-padding" href="/categories/数据可视化/数据降维/">
                    数据降维 <span class="right">1</span></a>
                </a>
            </li>

        

    </ul>
</div>

        </div>
    </div>
</nav>

<div id="search" class="modal search-modal">
    <div class="row">
        <div class="input-field col s12">
              <input id="search-input" type="text">
              <label for="search-input">Search</label>
        </div>

    </div>
    <div id="search-result" class="search-result col s12">

    </div>
</div>


    <main>
        <div class="container main-container">
    <nav class="page-nav hide-on-small-only">
    <div class="nav-wrapper indigo">
        <span class="breadcrumb">Current page(Categories)</span>
        
            
    
    
    <a class="breadcrumb" href="/categories/人工智能/">人工智能</a><a class="breadcrumb" href="/categories/人工智能/机器学习/">机器学习</a>


        

        
    </div>
</nav>

<article>
    <div class="card">
        <div class="card-content">
            

            <div class="article-title">
                
    
        <h1>Logistic Regression</h1>
    


            </div>
            <time class="pink-link-context" datetime="2016-05-21T16:00:00.000Z"><a href="/2016/05/22/logistic-regression/">2016-05-22</a></time>

            
    <div class="tags-row">
        
            <a href="/tags/机器学习/" class="chip pink lighten-1">机器学习</a>
        
            <a href="/tags/神经网络/" class="chip pink lighten-1">神经网络</a>
        
    </div>


            <div class="toc pink-link-context hide-on-med-and-down">
    <ol class="section table-of-contents"><li class="section table-of-contents-item section table-of-contents-level-1"><a class="section table-of-contents-link" href="#logistic-regression"><span class="section table-of-contents-text">Logistic Regression</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#学习准则"><span class="section table-of-contents-text">学习准则</span></a></li><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#梯度下降"><span class="section table-of-contents-text">梯度下降</span></a></li><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#logistic-regression-背后的概率原理"><span class="section table-of-contents-text">Logistic Regression 背后的概率原理</span></a></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-2"><a class="section table-of-contents-link" href="#代码实现"><span class="section table-of-contents-text">代码实现</span></a></li></ol></li></ol>
</div>


            <div class="entry pink-link-context">
                <h1 id="logistic-regression">Logistic Regression</h1>
<p>logistic regression 和 perceptron 其实是比较像的，都是只能对线性可分的数据建模，也是基于神经科学的神经元模型得来的，神经元模型图如下。不过 logistic regression 的输出结果值具有一定的解释性，可以把它理解为概率。另外一方面，logistic regression 可以很容易地扩展到对多个类建模，而 percptron 只能作为二元分类器。 logistic regression 使用 sigmoid 激活函数</p>
<p><span class="math display">\[\sigma = \frac{1}{1 + \exp^{-z}}\]</span> <a id="more"></a></p>
<p>如果更加深入的来说，对于输入为<span class="math inline">\(x_1,x_2,x_3,...\)</span>，权重为<span class="math inline">\(w_1,w_2,w_3,...\)</span>,偏置<span class="math inline">\(b\)</span>，则相对应的激活值为</p>
<p><span class="math display">\[\frac{1}{1 + \exp^{- \sum_i{w_ix_i} - b}}\]</span></p>
<div align="center" style="margin-bottom=20px">
<img src="/2016/05/22/logistic-regression/neuron_model.jpeg" alt="神经元模型" title="神经元模型">
</div>
<h3 id="学习准则">学习准则</h3>
<p>学习到的模型需要一个机制去评估参数<span class="math inline">\(w,b\)</span>是否比较好，所以说需要对我们做出的模型函数进行评估，一般这个函数称为损失函数（loss function）或者错误函数(error function)。假设模型拟合函数为<span class="math inline">\(h(\theta)\)</span>,那么在我们这个 logistic regression 模型中有<span class="math inline">\(h(\theta)=\sigma(w,b)\)</span>.描述模型函数<span class="math inline">\(h(\theta)\)</span>不好的程度，一般称这个函数为损失函数,通常情况下可以使用欧氏距离损失函数 <span class="math display">\[J(\theta)=\frac{1}{2} \sum_i^N{(h_{\theta}(x^i) - y^i)^2}\]</span> 只要最优化这个函数便可以得到在这个损失函数标准下的最好的模型。在机器学习方法中通常使用迭代的方法来逼近最有解，所以在这个算法里也使用了同样的思想。</p>
<h3 id="梯度下降">梯度下降</h3>
<p>在选定线性回归模型后，只需要确定参数<span class="math inline">\(\theta\)</span>，就可以将模型用来预测。然而θ需要在 <span class="math inline">\(J(\theta)\)</span>最小的情况下才能确定。因此问题归结为求极小值问题，使用梯度下降法。梯度下降法最大的问题是求得有可能是全局极小值，这与初始点的选取有关。 梯度下降法是按下面的流程进行的：</p>
<ol style="list-style-type: decimal">
<li>首先对<span class="math inline">\(\theta\)</span>赋值，这个值可以是随机的，也可以让<span class="math inline">\(\theta\)</span>是一个全零的向量。</li>
<li>改变<span class="math inline">\(\theta\)</span>的值，使得 <span class="math inline">\(J(\theta)\)</span>按梯度下降的方向进行减少。</li>
</ol>
<p>梯度方向由 <span class="math inline">\(J(\theta)\)</span>对<span class="math inline">\(\theta\)</span>的偏导数确定，由于求的是极小值，因此梯度方向是偏导数的反方向。结果为</p>
<p><span class="math display">\[\theta_j := \theta_j + \alpha(h_{\theta}(x^i - y^i))x_j^i\]</span></p>
<p>迭代更新的方式有两种，一种是批梯度下降，也就是对全部的训练数据求得误差后再对θ进行更新，另外一种是增量梯度下降，每扫描一步都要对θ进行更新。前一种方法能够不断收敛，后一种方法结果可能不断在收敛处徘徊。这次实现的算法中使用的是批梯度下降的方法。</p>
<h3 id="logistic-regression-背后的概率原理">Logistic Regression 背后的概率原理</h3>
<p>logistic regression 是人工神经网络中非常基础也是非常重要的一个模型，就算是深度学习中的深度神经网络中的决策层也 是经常使用 logistic 层或者<a href="https://en.wikipedia.org/wiki/Softmax_function" target="_blank" rel="external">softmax</a>层。在网上搜索基本上很少看到 有分析 logistic regression 原理性的中文博客文章，大多是直接上公式然后求梯度，只解释了怎么用，而不解释清楚什么情 况下可以用，为什么可以用，所以打算再深入的剖析 logistic regression 背后合理性，也加强自己的记忆。我们可能会问， 为何可以用<span class="math inline">\(\sigma\)</span>函数来做回归，并且符合哪些分布的数据用 logistic regression 能够得到较好的效果。 为了分析的简单，先分析两类的情况，其实也很容易拓展到多类。假设在每个类的条件下数据分布的密度函数为 <span class="math inline">\(p(\mathbf{x}|\mathcal{C}_k)\)</span>,每个类的先验概率为<span class="math inline">\(p(\mathcal{C}_k)\)</span>,那么我们的任务就是使用贝叶斯公式计算后验概 率<span class="math inline">\(p(\mathcal{C}_k|\mathbf{x})\)</span>.由于我们只考虑两类的情况，对于类<span class="math inline">\(\mathcal{C}_1\)</span>的后验概率可以写为</p>
<p><span class="math display">\[
\begin{aligned}
p(\mathcal{C}_1|\mathbf{x}) &amp;= \frac{p(\mathbf{x}|\mathcal{C}_1) p(\mathcal{C}_1)}
{p(\mathbf{x}|\mathcal{C}_1) p(\mathcal{C}_1) + p(\mathbf{x}|\mathcal{C}_2) p(\mathcal{C}_2)} \\
    &amp;= \frac{1}{1 + \exp(-a)} = \sigma(a)
\end{aligned}
\]</span></p>
<p>其中<span class="math inline">\(a\)</span>是一个非常关键的参数，整个模型都由这个参数来决定，定义为</p>
<p><span class="math display">\[ a = \ln{\frac{p(\mathbf{x}|\mathcal{C}_1) p(\mathcal{C}_1)}{p(\mathbf{x}|\mathcal{C}_2) p(\mathcal{C}_2)}} \]</span></p>
<p><span class="math inline">\(\sigma(a)\)</span>就是 logistic sigmoid 函数，定义为<span class="math inline">\(\sigma(a) = \frac{1}{1 + \exp(-a)}\)</span>很容易验证 logistic sigmoid 函数的逆为<span class="math inline">\(a = \ln(\frac{\sigma}{1-\sigma})\)</span> 这其实是一个<a href="https://en.wikipedia.org/wiki/Logit" target="_blank" rel="external">logit function</a>,表示两个类概率比率的对数<span class="math inline">\(\ln[p(\mathcal{C}_1|\mathbf{x})/p(\mathcal{C}_2|\mathbf{x})]\)</span> 对于多个类，也很容易得到每一个类的后验概率</p>
<p><span class="math display">\[
\begin{aligned}
p(\mathcal{C}_k | \mathbf{x}) &amp;= \frac{p(\mathbf{x}|\mathcal{C}_k) p(\mathcal{C}_k)}
{\sum_j{p(\mathbf{x}|\mathcal{C}_j) p(\mathcal{C}_j)}} \\
    &amp;= \frac{\exp(a_k)}{\sum_j{\exp(a_j)}}
\end{aligned}
\]</span></p>
<p>其中<span class="math inline">\(a_k\)</span>为</p>
<p><span class="math display">\[ a_k = \ln p(\mathbf{x}|\mathcal{C}_k) p(\mathcal{C}_k) \]</span></p>
<p>其实这个函数也就是 softmax 函数。</p>
<p>从上面的分析看，对于两类的情况(多类也同理)，每个类的后验概率就是 logistic sigmoid 函数，单<span class="math inline">\(a\)</span>是线性的时候，也就是<span class="math inline">\(a = \ln{\frac{p(\mathbf{x}|\mathcal{C}_1) p(\mathcal{C}_1)}{p(\mathbf{x}|\mathcal{C}_2) p(\mathcal{C}_2)}}\)</span>是线性时，我们便可以使用 logistic regression 来对数据集做回归分析，这样就能得到很好的效果。这样说可能还有点模糊，因为我们很难知道一个分布中<span class="math inline">\(a = \ln{\frac{p(\mathbf{x}|\mathcal{C}_1) p(\mathcal{C}_1)}{p(\mathbf{x}|\mathcal{C}_2) p(\mathcal{C}_2)}}\)</span>是不是线性的，其实只要是<a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="external">指数族</a>分布就可以用 logistic regression 来做回归，这里就不解释原因了，具体可以参考 Christopher M. Bishop 的<strong>Pattern Recognition And Machine Learning</strong></p>
<p>sigmoid 激活函数如下图</p>
<div align="center" style="margin-bottom:20px">
<img src="/2016/05/22/logistic-regression/sigmoid.png" alt="sigmoid.png" title="">
</div>
<h2 id="代码实现">代码实现</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> cPickle <span class="keyword">as</span> pkl</span><br><span class="line"></span><br><span class="line">__author__ = <span class="string">'wangzx'</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dim, n_class=<span class="number">2</span>)</span>:</span></span><br><span class="line">        self.n_class = n_class</span><br><span class="line">        self.dim = dim</span><br><span class="line">        self.biases = np.random.randn(n_class, <span class="number">1</span>)</span><br><span class="line">        self.weights = np.random.randn(n_class, dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedforward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        fd = sigmoid(np.dot(self.weights, x)+self.biases)</span><br><span class="line">        <span class="keyword">return</span> fd / np.sum(fd)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">SGD</span><span class="params">(self, training_data, epochs, mini_batch_size, eta,</span><br><span class="line">            test_data=None)</span>:</span></span><br><span class="line">        <span class="string">"""使用 mini-batch stochastic gradient descent 方法训练网络。</span><br><span class="line">        ``training_data``是一个列表元组``（x,y）``,代表训练的输入和目标输出。</span><br><span class="line">        如果提供``test_data``的话，在每一个 epoch 完成之后会用模型计算这个数据相对应的</span><br><span class="line">        输出。这个可以让我们更清楚整个训练情况，不过会降低训练的速度。</span><br><span class="line">        """</span></span><br><span class="line">        <span class="keyword">if</span> test_data: n_test = len(test_data)</span><br><span class="line">        n = len(training_data)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> xrange(epochs):</span><br><span class="line">            random.shuffle(training_data)</span><br><span class="line">            mini_batches = [</span><br><span class="line">                training_data[k:k+mini_batch_size]</span><br><span class="line">                <span class="keyword">for</span> k <span class="keyword">in</span> xrange(<span class="number">0</span>, n, mini_batch_size)]</span><br><span class="line">            <span class="keyword">for</span> mini_batch <span class="keyword">in</span> mini_batches:</span><br><span class="line">                self.update_mini_batch(mini_batch, eta)</span><br><span class="line">            <span class="keyword">if</span> test_data:</span><br><span class="line">                print(<span class="string">"Epoch &#123;0&#125;: &#123;1&#125; / &#123;2&#125;"</span>.format(</span><br><span class="line">                    j, self.evaluate(test_data), n_test))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">"Epoch &#123;0&#125; complete"</span>.format(j))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_mini_batch</span><span class="params">(self, mini_batch, eta)</span>:</span></span><br><span class="line">        <span class="string">"""通过随机梯度下降的方法来更新权值。</span><br><span class="line">        ``mini_batch``是一个元组列表``(x,y)``,每一项是一个训练数据，分别代表</span><br><span class="line">        训练输入和目标输出，``eta``是学习率"""</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># nabla_b 和 nabla_w 分别表示 b 和 w 的梯度</span></span><br><span class="line">        nabla_b = np.zeros_like(self.biases)</span><br><span class="line">        nabla_w = np.zeros_like(self.weights)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> mini_batch:</span><br><span class="line">            delta_nabla_b, delta_nabla_w = self.backprop(x, y)</span><br><span class="line">            nabla_b += delta_nabla_b</span><br><span class="line">            nabla_w += delta_nabla_w</span><br><span class="line"></span><br><span class="line">        self.weights -= eta / len(mini_batch) * nabla_w</span><br><span class="line">        self.biases -= eta / len(mini_batch) * nabla_b</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backprop</span><span class="params">(self, x, y)</span>:</span></span><br><span class="line">        <span class="string">"""其实可以不用写一个 backprop 函数，直接算梯度就行了，不过为了和 bp 神经网络</span><br><span class="line">        的代码结构尽量保持相似，所以也写了一个 backprop 函数"""</span></span><br><span class="line">        <span class="comment"># feedforward</span></span><br><span class="line">        activation = self.feedforward(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># backward pass</span></span><br><span class="line">        delta = self.cost_derivative(activation, y) * \</span><br><span class="line">            sigmoid_prime(np.dot(self.weights, x) + self.biases)</span><br><span class="line">        <span class="keyword">return</span> delta, np.dot(delta, x.T)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(self, test_data)</span>:</span></span><br><span class="line">        <span class="string">"""返回预测准确的样本个数"""</span></span><br><span class="line">        test_results = [(np.argmax(self.feedforward(x)), y)</span><br><span class="line">                        <span class="keyword">for</span> (x, y) <span class="keyword">in</span> test_data]</span><br><span class="line">        <span class="keyword">return</span> sum(int(x == y) <span class="keyword">for</span> (x, y) <span class="keyword">in</span> test_results)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_derivative</span><span class="params">(self, output_activations, y)</span>:</span></span><br><span class="line">        <span class="comment"># 因为 y 是一个常数值，要转为 one-hot 编码</span></span><br><span class="line">        t = np.zeros((self.n_class, <span class="number">1</span>))</span><br><span class="line">        t[y, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#使用欧氏距离损失函数，其导数如下</span></span><br><span class="line">        <span class="keyword">return</span> (output_activations-t)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Miscellaneous functions</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="string">"""sigmoid 函数."""</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1.0</span>+np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_prime</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="string">"""sigmoid 函数的导数."""</span></span><br><span class="line">    <span class="keyword">return</span> sigmoid(z)*(<span class="number">1</span>-sigmoid(z))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">    feat = pkl.load(open(<span class="string">"data/train_X.pkl"</span>, <span class="string">'rb'</span>))</span><br><span class="line">    <span class="comment">#对数据进行归一化处理</span></span><br><span class="line">    feat = (feat - np.min(feat, axis=<span class="number">0</span>)) / (np.max(feat, axis=<span class="number">0</span>) - np.min(feat, axis=<span class="number">0</span>) + <span class="number">1e-3</span>)</span><br><span class="line">    y = pkl.load(open(<span class="string">"data/train_Y.pkl"</span>, <span class="string">'rb'</span>))</span><br><span class="line">    train_data = [(np.asarray(f).reshape((<span class="number">-1</span>,<span class="number">1</span>)), t) <span class="keyword">for</span> f, t <span class="keyword">in</span> zip(feat, y)]</span><br><span class="line">    test_feat = pkl.load(open(<span class="string">"data/test_X.pkl"</span>, <span class="string">'rb'</span>))</span><br><span class="line">    test_feat = (test_feat - np.min(test_feat, axis=<span class="number">0</span>)) / \</span><br><span class="line">                (np.max(test_feat, axis=<span class="number">0</span>) - np.min(test_feat, axis=<span class="number">0</span>) + <span class="number">1e-3</span>)</span><br><span class="line">    test_y = pkl.load(open(<span class="string">"data/test_Y.pkl"</span>, <span class="string">'rb'</span>))</span><br><span class="line">    test_data = [(np.asarray(f).reshape((<span class="number">-1</span>,<span class="number">1</span>)), t) <span class="keyword">for</span> f, t <span class="keyword">in</span> zip(test_feat, test_y)]</span><br><span class="line">    n_sample, ndim = feat.shape</span><br><span class="line">    logistic = LogisticRegression(ndim)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Begin fit training data"</span>)</span><br><span class="line">    logistic.SGD(train_data, <span class="number">50</span>, <span class="number">50</span>, <span class="number">0.01</span>, test_data)</span><br><span class="line"></span><br><span class="line">    score = logistic.evaluate(test_data) / len(test_data)</span><br><span class="line">    print(<span class="string">"Test accuracy is %f"</span> % score)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_mnist</span><span class="params">()</span>:</span></span><br><span class="line">    path = <span class="string">'/home/wangzx/usr/share/data/mnist2/'</span></span><br><span class="line">    train_X = pkl.load(open(path + <span class="string">'mnist_train_X.pkl'</span>))</span><br><span class="line">    train_y = pkl.load(open(path + <span class="string">'mnist_train_y.pkl'</span>)).ravel()</span><br><span class="line">    test_X = pkl.load(open(path + <span class="string">'mnist_test_X.pkl'</span>))</span><br><span class="line">    test_y = pkl.load(open(path + <span class="string">'mnist_test_y.pkl'</span>)).ravel()</span><br><span class="line">    train_data = [(np.asarray(f).reshape((<span class="number">-1</span>,<span class="number">1</span>)), t) <span class="keyword">for</span> f, t <span class="keyword">in</span> zip(train_X, train_y)]</span><br><span class="line">    test_data = [(np.asarray(f).reshape((<span class="number">-1</span>,<span class="number">1</span>)), t) <span class="keyword">for</span> f, t <span class="keyword">in</span> zip(test_X, test_y)]</span><br><span class="line">    n_sample, ndim = train_X.shape</span><br><span class="line">    logistic = LogisticRegression(ndim, n_class=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Begin fit training data"</span>)</span><br><span class="line">    logistic.SGD(train_data, <span class="number">50</span>, <span class="number">50</span>, <span class="number">0.02</span>, test_data)</span><br><span class="line"></span><br><span class="line">    score = logistic.evaluate(test_data) / len(test_data)</span><br><span class="line">    print(<span class="string">"Test accuracy is %f"</span> % score)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment">#test()</span></span><br><span class="line">    <span class="comment">#test_mnist()</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

            </div>
        </div>
    </div>
</article>




    <section id="comment">
        <div class="card">
            <div class="card-content">
                <!-- Duoshuo Comment BEGIN -->
                <div class="ds-thread" data-thread-key="2016/05/22/logistic-regression/" data-title="Logistic Regression" data-url="http://shuimuth.github.io/2016/05/22/logistic-regression/"></div>

                <script type="text/javascript">
                    console.log(document.querySelector('.ds-thread'));
                    var duoshuoQuery = {
                        short_name: 'shuimuth'
                    };
                    (function() {
                        var ds = document.createElement('script');
                        ds.type = 'text/javascript';
                        ds.async = true;
                        ds.src = (document.location.protocol == 'https:'
                            ? 'https:'
                            : 'http:') + '//static.duoshuo.com/embed.js';
                        ds.charset = 'UTF-8';
                        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
                    })();
                </script>
                <!-- Duoshuo Comment END -->
            </div>
        </div>
    </section>



</div>

        <div class="fixed-action-btn float-sitemap">
    <a class="btn-floating btn-large pink">
      <i class="fa fa-caret-square-o-up"></i>
    </a>
    <ul>
      <li><a class="btn-return-top btn-floating waves-effect green" title="Return to top"><i class="fa fa-arrow-circle-o-up"></i></a></li>
      <li><a class="btn-floating waves-effect button-collapse yellow darken-1"  data-activates="main-menu" title="menu"><i class="fa fa-navicon"></i></a></li>
    </ul>
  </div>

    </main>
    <footer class="page-footer indigo darken-1">
    
    <div class="container">
        <div class="row">
            
            <div class="social-group col m3 s12">
                <h5 class="white-text">Social</h5>
                
                    <a class="social-link" href="https://github.com/shuimuth" target="_blank">
                        <i class="fa fa-2x fa-github"></i>
                    </a>
                
            </div>
            

            
            <div class="col m9 s12">
                <h5 class="white-text">Links</h5>
                
                    <a class="social-link" href="http://raytaylorlin.com/" target="_blank">raytaylorism主题作者的技术博客</a>
                
            </div>
            
        </div>
    </div>
    

    <div class="footer-copyright pink-link-context">
        <div class="container">
            © 2016 example.com, All rights reserved.
            <p class="right" style="margin-top: 0;">Blog powered by <a href="https://hexo.io">Hexo</a> | Theme <a href="https://github.com/raytaylorlin/hexo-theme-raytaylorism">raytaylorism</a></p>
        </div>
    </div>
</footer>


    <noscript>
    <div class="noscript">
        <p class="center-align">当前网速较慢或者你使用的浏览器不支持博客特定功能，请尝试刷新或换用Chrome、Firefox等现代浏览器</p>
    </div>
</noscript>
<div class="noscript">
    <p class="center-align">当前网速较慢或者你使用的浏览器不支持博客特定功能，请尝试刷新或换用Chrome、Firefox等现代浏览器</p>
</div>


<script src="/js/jquery-2.1.1.min.js"></script>
<script src="/js/materialize.min.js"></script>

<script>
    (function($) {
        $(document).ready(function() {
            // 隐藏禁用javascript（针对微信内置浏览器）的提示
            $('.noscript').hide();

            // 图片缩放效果
            var $imgs = $('img').not('.slider-image').not('.avatar-image').not('.carousel-image').not('.card-cover-image').not('.qrcode');

            // 给图片加上点击放大效果（materialbox插件）
            $imgs.addClass('materialboxed').each(function(i, el) {
                $(this).attr('data-caption', $(this).attr('alt') || ' ');
            }).materialbox();

            // 优化表格的显示
            $('table').each(function() {
                var $table = $(this);
                // 除去多行代码的情况
                if ($table.find('pre').length == 0) {
                    $table.addClass('responsive-table striped bordered');
                }
            });

            // 首页幻灯片
            $('.slider').slider({indicators: true, full_width: true, interval: 8000});

            $(".button-collapse").sideNav();
            $(".category-menu").sideNav();

            // 针对gallery post
            $('.carousel').carousel({full_width: true});
            $('.carousel-control.prev').click(function() {
                $('.carousel').carousel('prev');
            });
            $('.carousel-control.next').click(function() {
                $('.carousel').carousel('next');
            });

            // 文章目录
            $('article').not('.simple-article').find('h1').add('h2').add('h3').add('h4').add('h5').add('h6').scrollSpy();
            // 修正文章目录的left-border颜色
            var color = $('.table-of-contents-text').css('color');
            $('.table-of-contents-link').css('border-left-color', color);

            // 针对移动端做的优化：FAB按钮点击一下收回
            if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
                $('.fixed-action-btn').addClass('click-to-toggle');
            }
            // 回到顶部
            $('.btn-return-top').click(function() {
                $('body, html').animate({
                    scrollTop: 0
                }, 500);
            });

            // 重置读书页面的Tab标签页的颜色
            $('li.tab a').hover(function() {
                $(this).toggleClass('text-lighten-4');
            });
            $('.indicator').addClass('pink lighten-2');

            
            // 添加new标签
            $('').append('<span class="new badge pink"></span>');
            

            // 搜索功能
            $('.modal-trigger').leanModal({
                // 打开搜索框时自动聚焦
                ready: function() {
                    if ($('#search').is(":visible")) {
                        $('#search-input').focus();
                    }
                }
            });
            var searchXml = "search.xml";
            if (searchXml.length == 0) {
             	searchXml = "search.xml";
            }
            var searchPath = "/" + searchXml;
            initSearch(searchPath, 'search-input', 'search-result');
        });

        // 初始化搜索与匹配函数
        var initSearch = function(path, search_id, content_id) {
            'use strict';
            $.ajax({
                url: path,
                dataType: "xml",
                success: function(xmlResponse) {
                    // get the contents from search data
                    var datas = $("entry", xmlResponse).map(function() {
                        return {
                            title: $("title", this).text(),
                            content: $("content", this).text(),
                            url: $("url", this).text()
                        };
                    }).get();
                    var $input = document.getElementById(search_id);
                    var $resultContent = document.getElementById(content_id);
                    $input.addEventListener('input', function() {
                        var str = '<ul class=\"search-result-list\">';
                        var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                        $resultContent.innerHTML = "";
                        if (this.value.trim().length <= 0) {
                            return;
                        }
                        // perform local searching
                        datas.forEach(function(data) {
                            var isMatch = true;
                            var content_index = [];
                            var data_title = data.title.trim().toLowerCase();
                            var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                            var data_url = data.url;
                            var index_title = -1;
                            var index_content = -1;
                            var first_occur = -1;
                            // only match artiles with not empty titles and contents
                            if (data_title != '' && data_content != '') {
                                keywords.forEach(function(keyword, i) {
                                    index_title = data_title.indexOf(keyword);
                                    index_content = data_content.indexOf(keyword);
                                    if (index_title < 0 && index_content < 0) {
                                        isMatch = false;
                                    } else {
                                        if (index_content < 0) {
                                            index_content = 0;
                                        }
                                        if (i == 0) {
                                            first_occur = index_content;
                                        }
                                    }
                                });
                            }
                            // show search results
                            if (isMatch) {
                                keywords.forEach(function(keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    data_title = data_title.replace(regS, "<span class=\"search-keyword pink lighten-2\">" + keyword + "</span>");
                                });

                                str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                                var content = data.content.trim().replace(/<[^>]+>/g, "");
                                if (first_occur >= 0) {
                                    // cut out 100 characters
                                    var start = first_occur - 20;
                                    var end = first_occur + 80;
                                    if (start < 0) {
                                        start = 0;
                                    }
                                    if (start == 0) {
                                        end = 100;
                                    }
                                    if (end > content.length) {
                                        end = content.length;
                                    }
                                    var match_content = content.substring(start, end);
                                    // highlight all keywords
                                    keywords.forEach(function(keyword) {
                                        var regS = new RegExp(keyword, "gi");
                                        match_content = match_content.replace(regS, "<span class=\"search-keyword pink lighten-2\">" + keyword + "</span>");
                                    });

                                    str += "<p class=\"search-result\">..." + match_content + "...</p>"
                                }
                                str += "</li>";
                            }
                        });
                        str += "</ul>";
                        $resultContent.innerHTML = str;
                    });
                }
            });
        }
    })(jQuery);
</script>


<script src="/js/prettify.js"></script>
<script type="text/javascript">
    $(document).ready(function() {
        $("pre").addClass("prettyprint");
        prettyPrint();
    });
</script>




<script type="text/javascript" src="http://tajs.qq.com/stats?sId=56341338" charset="UTF-8"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



</body>
</html>
